---
layout: post
comments: false
publish: false
title: You're Deploying it Wrong! - AS Edition (Part 2)
date: 2019-03-23
author: Daniel Otykier
authorurl: http://twitter.com/dotykier
---

This is part 2 of the Analysis Services DevOps blog series.

## Branching strategy and workflow

The first thing we need to align before getting started, is what branching strategy to use. While this sounds boring, it's actually quite important, because it will dictate what the daily development workflow will be like, and in many cases, branches will tie directly into the project methods used by your team. For example, using the [agile process within Azure DevOps](https://docs.microsoft.com/en-us/azure/devops/boards/work-items/guidance/agile-process?view=azure-devops), your backlog would consist of **Epics**, **Features**, **User Stories**, **Tasks** and **Bugs** (well, hopefully not too many Bugs, since we're going to automate testing as part of our DevOps journey).

In the agile terminology, a **User Story** is a deliverable, testable piece of work. The User Story may consist of several **Tasks**, that are smaller pieces of work that need to be performed, typically by a developer, before the User Story may be delivered. In the ideal world, all User Stories have been broken down into manageable tasks, each taking only a couple of hours to complete, adding up to no more than a handful of days for the entire User Story. This would make a User Story an ideal candidate for a so-called [Topic Branch](https://git-scm.com/book/en/v2/Git-Branching-Branching-Workflows), where the developer could make one or more commits for each of the tasks within the User Story. Once all tasks are done, you want to deliver the User Story to the client, at which time the topic branch is merged into a delivery branch (for example, a "Test" branch), and the code deployed to a testing environment.

Determining a suitable branching strategy depends on many different factors. In general, Microsoft recommends the [Trunk-based Development](https://docs.microsoft.com/en-us/azure/devops/repos/git/git-branching-guidance?view=azure-devops) ([video](https://youtu.be/t_4lLR6F_yk?t=232)) strategy, for agile and continuous delivery of small increments. The main idea is to create branches off the **Master** branch for every new feature or bugfix (see image below). Code review processes are enforced through pull requests from feature branches into Master, and using the [Branch Policy](https://docs.microsoft.com/en-us/azure/devops/repos/git/branch-policies?view=azure-devops) feature of Azure DevOps, we can set up rules that require code to build cleanly before a pull request can be completed.

![Trunk-based Development](https://user-images.githubusercontent.com/8976200/54871798-75601e00-4dba-11e9-81af-77faf12de8a7.png)

However, such a strategy might not be feasible in a Business Intelligence development team, for a number of reasons:

- New features often require prolonged testing and validation by business users, which may take several weeks to complete. As such, you will likely need a user-faced test environment.
- BI solutions are multi-tiered, typically consisting of a Data Warehouse tier with ETL, a Master Data Management tier, a semantic layer and reports. Dependencies exist between these layers, that further complicate testing and deployment.
- The BI team may be responsible for developing and maintaining several different semantic models, serving different areas of business (Sales, Inventory, Logistics, Finance, HR, etc.), at different maturity stages and at varying development pace.
- The most important aspect of a BI solution is the **data**! As a BI developer, you don't have the luxury of simply checking out the code from source control, hitting F5 and having a full solution up and running in the few minutes it takes to compile the code. *Your solution needs data*, and that data has to be loaded, ETL'ed or processed across several layers to make it to the end user. Including data in your DevOps workflows could blow up build and deployment times from minutes to hours or even days. In some scenarios, it might not even be possible, due to ressource or economy constraints.

There's no doubt that a BI team would benefit from a branching strategy that supports parallel development on any of the layers in the full BI solution, in a way that lets us mix and match features that are ready for testing. But especially due to the last bullet point above, we need to think carefully about how we're going to handle the data. If we add a new attribute to a dimension, for example, do we want to automatically load the dimension as part of our build and deployment pipelines? If it only takes a few minutes to load such a dimension, that would probably be fine, but what if we're adding a new column to a multi-billion row fact table? And if developers are working on new features in parallel, should each developer have their own development database, or how do we otherwise prevent them from stepping on each others toes in a shared database?

There's no easy solution to the questions above - especially when considering all the tiers of a BI solution, and the different constellations and prefered workflows of BI teams across the planet. As the title suggests, we're going to focus on Analysis Services - the semantic layer of the solution - for this blog series. Since this tier typically holds a lot of data (well, unless you're running everything in DirectQuery mode), the principles that come into play could theoretically be extended to other layers of the full BI stack as well. Before concluding the blog series, we will try to describe, at a high level, how this can be done.

### GitFlow branching and deployment environments

For this blog series, we're going to use the [GitFlow branching strategy by Vincent Driessen](https://nvie.com/posts/a-successful-git-branching-model/). If you're not already familiar with this pattern, I strongly recommend reading the article.

<img src="https://user-images.githubusercontent.com/8976200/56668663-33bfdd00-66b0-11e9-8fd1-ea8e273ce8b2.png" width="400" />

Implementing a branching strategy similar to this, can help solve some of the DevOps problems typically encountered by BI teams, provided you put some thought into how the branches correlate to your deployment environments. The HEAD of the *master* branch should correspond to the code deployed to your production environment, that much is clear. But where should code in your *develop* branch be deployed? And how do you make code in one or more of your feature branches available for testing and validation by business users? What if the data volumes involved are so large, that it is not practical to replicate everything across several environments, due to resource or economy constraints? What if you're working in a non-virtual on-premises environment, in which you can't simply spin up a new instance of Analysis Services for testing purposes?

I'm afraid there's not really any "one-size-fits-all" solution to these considerations.

## Repository structure

```
bi/
├── sql-dwh/
│   ├── dwh.sqlproj
│   ├── tables/
│   ├── views/
│   └── stored procesdures/
├── adf-etl/
│   ├── pipeline/
│   ├── linkedService/
│   └── dataset/
└── as-tabular/
    ├── retail/
    │   ├── database.json
    │   ├── tables/
    │   ├── relationships/
    │   └── dataSources/
    ├── finance/
    └── hr/
```
