---
layout: post
comments: false
publish: false
title: You're Deploying it Wrong! - AS Edition (Part 2)
date: 2019-03-23
author: Daniel Otykier
authorurl: http://twitter.com/dotykier
---

This is part 2 of the Analysis Services DevOps blog series.

## Branching strategy and workflow

The first thing we need to align before getting started, is what branching strategy to use. While this sounds boring, it's actually quite important, because it will dictate what the daily development workflow will be like, and in many cases, branches will tie directly into the project methods used by your team. For example, using the [agile process within Azure DevOps](https://docs.microsoft.com/en-us/azure/devops/boards/work-items/guidance/agile-process?view=azure-devops), your backlog would consist of **Epics**, **Features**, **User Stories**, **Tasks** and **Bugs** (well, hopefully not too many Bugs, since we're going to automate testing as part of our DevOps journey).

In the agile terminology, a **User Story** is a deliverable, testable piece of work. The User Story may consist of several **Tasks**, that are smaller pieces of work that need to be performed, typically by a developer, before the User Story may be delivered. In the ideal world, all User Stories have been broken down into manageable tasks, each taking only a couple of hours to complete, adding up to no more than a handful of days for the entire User Story. This would make a User Story an ideal candidate for a so-called [Topic Branch](https://git-scm.com/book/en/v2/Git-Branching-Branching-Workflows), where the developer could make one or more commits for each of the tasks within the User Story. Once all tasks are done, you want to deliver the User Story to the client, at which time the topic branch is merged into a delivery branch (for example, a "Test" branch), and the code deployed to a testing environment.

Determining a suitable branching strategy depends on many different factors. In general, Microsoft recommends the [Trunk-based Development](https://docs.microsoft.com/en-us/azure/devops/repos/git/git-branching-guidance?view=azure-devops) ([video](https://youtu.be/t_4lLR6F_yk?t=232)) strategy, for agile and continuous delivery of small increments. The main idea is to create branches off the **Master** branch for every new feature or bugfix (see image below). Code review processed are enforced through pull requests from feature branches into Master, and using the [Branch Policy](https://docs.microsoft.com/en-us/azure/devops/repos/git/branch-policies?view=azure-devops) feature of Azure DevOps, we can set up rules that require code to build cleanly before a pull request can be completed.

![Trunk-based Development](https://user-images.githubusercontent.com/8976200/54871798-75601e00-4dba-11e9-81af-77faf12de8a7.png)

However, such a strategy might not be feasible in a Business Intelligence development team, for a number of reasons:

- New features often require prolonged testing and validation by business users, which may take several weeks to complete. As such, you will likely need a user-faced test environment.
- BI solutions are multi-tiered, typically consisting of a Data Warehouse tier with ETL, a Master Data Management tier, a semantic layer and reports. Dependencies exist between these layers, that further complicate testing and deployment.
- The BI team may be responsible for developing and maintaining several different semantic models, serving different areas of business (Sales, Inventory, Logistics, Finance, HR, etc.), at different maturity stages and at varying development pace.
- The most important aspect of a BI solution is the **data**! As a BI developer, you don't have the luxury of simply checking out the code from source control, hitting F5 and having a full solution up and running in the few minutes it takes to compile the code. *Your solution needs data*, and that data has to be loaded, ETL'ed or processed across several layers to make it to the end user. Including data in your DevOps workflows could blow up build and deployment times from minutes to hours or even days. In some scenarios, it might not even be possible, due to ressource constraints.

There's no doubt that a BI team would benefit from a branching strategy that supports parallel development on any of the layers in the full BI solution, in a way that lets us mix and match features that are ready for testing. But especially due to the last bullet point above, we need to think carefully about how we're going to handle the data. If we add a new attribute to a dimension, for example, do we want to automatically load the dimension as part of our build and deployment pipelines? If it only takes a few minutes to load such a dimension, that would probably be fine, but what if we're adding a new column to a multi-billion row fact table? And if developers are working on new features in parallel, should each developer have their own development database, or how do we otherwise prevent them from stepping on each others toes in a shared database?

There's no easy solution to the questions above - especially when considering all the tiers of a BI solution. As the title suggests, we're going to focus on Analysis Services - the semantic layer of the solution - for this blog series. Since this tier typically holds a lot of data (well, unless you're running everything in DirectQuery mode), the principles that come into play could theoretically be extended to other layers of the full BI stack as well. Before concluding the blog series, we will try to describe, at a high level, how this can be done.

## Ressource constraints

Let's say you've built a tabular model that takes up 10 GB of memory at rest. Since you're running your IT in the cloud, you would land on an [S1 AAS-instance](https://azure.microsoft.com/en-us/pricing/details/analysis-services/), which has 25 GB of memory, to make sure that there's enough room for processing and peak user loads. At 1.5K USD per month, this is quite an expenditure for your company, and you're not really excited on the outlook of having to spin up multiple new instances for feature development. Can a suitable branching strategy help us out here?

/// TODO: Rework all of the above. Trunk-based or GitFlow?!? Update: Not trunk-based, as it relies on feature flags, which we can't use on a tabular model. This is better: https://nvie.com/posts/a-successful-git-branching-model/

## Repository structure

```
bi/
├── sql-dwh/
│   ├── dwh.sqlproj
│   ├── tables/
│   ├── views/
│   └── stored procesdures/
├── adf-etl/
│   ├── pipeline/
│   ├── linkedService/
│   └── dataset/
└── as-tabular/
    ├── retail/
    │   ├── database.json
    │   ├── tables/
    │   ├── relationships/
    │   └── dataSources/
    ├── finance/
    └── hr/
```
